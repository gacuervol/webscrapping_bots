{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numero aleatorios entre 3 y 7\n",
    "def distriProb_lognorm():\n",
    "  pdf = np.random.lognormal(mean=2.0, sigma=0.5, size=(1))\n",
    "  if pdf<3  or pdf>7:\n",
    "    pdf=np.random.randint(3,6)\n",
    "  return float(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define el nevegador\n",
    "options = webdriver.ChromeOptions()\n",
    "#options.add_argument('--headless')\n",
    "#options.add_argument('--no-sandbox')\n",
    "#options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_driver = \"./chromedriver\"\n",
    "options.binary_location = \"/usr/bin/google-chrome-stable\"\n",
    "webpage_target = 'https://www.sciencedirect.com/'\n",
    "driver = webdriver.Chrome(options = options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colocamos el link de la pagina donde queremos hacer la busqueda\n",
    "try:\n",
    "    driver.get(webpage_target)\n",
    "except:\n",
    "    print('Hubo un error de conexion intentando de nuevo...')\n",
    "    time.sleep(distriProb_lognorm())\n",
    "    driver.refresh()\n",
    "    driver.get(webpage_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enviamos un query de busqueda a la barra de busqueda\n",
    "search_box_id = 'qs'\n",
    "query = 'eddies'\n",
    "search_box = driver.find_element(By.ID, search_box_id)\n",
    "search_box.send_keys(query)\n",
    "search_box.send_keys(Keys.RETURN) #click enter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hubo un error de conexion intentando de nuevo...\n"
     ]
    }
   ],
   "source": [
    "# Filtramos los resultados por los que corresponden a reviewa\n",
    "try:\n",
    "    time.sleep(distriProb_lognorm())\n",
    "    reviews = driver.find_element(By.ID, \"articleTypes-REV\")\n",
    "    driver.execute_script(\"arguments[0].click();\", reviews)\n",
    "except:\n",
    "    print('Hubo un error de conexion intentando de nuevo...')\n",
    "    time.sleep(10)\n",
    "    driver.refresh()\n",
    "    reviews = driver.find_element(By.ID, \"articleTypes-REV\")\n",
    "    driver.execute_script(\"arguments[0].click();\", reviews)\n",
    "try:\n",
    "    time.sleep(distriProb_lognorm())\n",
    "    earth = driver.find_element(By.ID, \"subjectAreas-1900\")\n",
    "    driver.execute_script(\"arguments[0].click();\", earth)\n",
    "except:\n",
    "    print('Hubo un error de conexion intentando de nuevo...')\n",
    "    time.sleep(10)\n",
    "    driver.refresh()\n",
    "    time.sleep(10)\n",
    "    show_more = driver.find_element(By.CSS_SELECTOR, '[aria-label=\"Show more subjectAreas filters\"]')\n",
    "    driver.execute_script(\"arguments[0].click();\", show_more)\n",
    "    time.sleep(distriProb_lognorm())\n",
    "    earth = driver.find_element(By.ID, \"subjectAreas-1900\")\n",
    "    driver.execute_script(\"arguments[0].click();\", earth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11566/140653954.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return float(pdf)\n"
     ]
    }
   ],
   "source": [
    "# Definimos 100 articulos por pagina\n",
    "time.sleep(distriProb_lognorm())\n",
    "xpath_100 = \"//a[@class='anchor' and @data-aa-name='srp-100-results-per-page']\"\n",
    "first_100 = driver.find_element(By.XPATH, xpath_100)\n",
    "driver.execute_script(\"arguments[0].click();\", first_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11566/140653954.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return float(pdf)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1019\n"
     ]
    }
   ],
   "source": [
    "# Extreamos el html\n",
    "time.sleep(distriProb_lognorm())\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "art_html = soup.find_all('a', 'anchor result-list-title-link u-font-serif text-s anchor-default', 'rev')\n",
    "pages_html = soup.find(id=\"srp-pagination\")\n",
    "n_pg = re.findall(r'Page\\s\\d of\\s(\\d+)', str(pages_html))[0]\n",
    "link_list = [link.get('href') for link in art_html]\n",
    "# Itera sobre cada pagina de los resultados de busqueda\n",
    "for _ in range(int(n_pg)-1):\n",
    "    # Siguiente pagina\n",
    "    time.sleep(distriProb_lognorm())\n",
    "    xpath_next = \"//a[@class='anchor' and @data-aa-name='srp-next-page']\"\n",
    "    next_100 = driver.find_element(By.XPATH, xpath_next)\n",
    "    driver.execute_script(\"arguments[0].click();\", next_100)\n",
    "    # Extreamos el html\n",
    "    time.sleep(distriProb_lognorm())\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    art_html = soup.find_all('a', 'anchor result-list-title-link u-font-serif text-s anchor-default', 'rev')\n",
    "    # Extreamos el link del html\n",
    "    next_link_list = [link.get('href') for link in art_html]\n",
    "    # Se añade a una lista\n",
    "    link_list.extend(next_link_list)\n",
    "    print(len(link_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11566/140653954.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return float(pdf)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\r"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'link': link_list})\n",
    "df['link'] = df['link'].map(lambda link: 'https://www.sciencedirect.com'+link)\n",
    "abstracts = []\n",
    "titles = []\n",
    "for link in df['link']:\n",
    "    #driver = webdriver.Chrome(executable_path = chrome_driver, options = options)\n",
    "    time.sleep(distriProb_lognorm())\n",
    "    driver.get(link)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    html_title = soup.find_all('span', 'title-text')\n",
    "    title_text = re.findall(r\"(?<=\\>).+(?=<)\", str(html_title))\n",
    "    titles.extend(title_text)\n",
    "    rexp = re.compile(r\"(?<=\\d\\\"\\>)\\w[A-Za-z\\s$&+,:;=?@#|'.^*()%!-’]+\\.\")\n",
    "    html_abstract = soup.find_all('div', 'abstract author')\n",
    "    abstract_text = re.findall(rexp, str(html_abstract))\n",
    "    abstracts.extend(abstract_text)\n",
    "    print(len(abstracts), end='\\r')\n",
    "df['titles'] = titles\n",
    "df['abstracts'] = abstracts\n",
    "df.to_csv('abstract_pln.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oceanenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
